{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgZu6HPcICWh"
      },
      "source": [
        "<h2 style=\"text-align:center;font-size:200%;;\">Pyspark для исследовательского анализа данных </h2>\n",
        "<h3  style=\"text-align:center;\">\n",
        "\n",
        "<span class=\"label label-success\">- Ленивая оценка</span>\n",
        "\n",
        "<span class=\"label label-success\">- Регистрация UDF</span>\n",
        "\n",
        "<span class=\"label label-success\">- Spark RDD</span>\n",
        "\n",
        "<span class=\"label label-success\">- Обработка данных</span>\n",
        "\n",
        "<span class=\"label label-success\">- Анализ данных</span>\n",
        "\n",
        "<span class=\"label label-success\">- Визуализация данных</span></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N751puSICWk"
      },
      "source": [
        "## Преимущества изучения Pyspark\n",
        "\n",
        "* Если компания планирует реализовать проект с действительно большим набором данных, Spark — <font color=\"red\"><b>отличный выбор</b></font> .\n",
        "Сравнительный анализ использования большого объема данных между `Pyspark` и `Pandas` по данным Датабрикс:  \n",
        "![Spark_vs_Pandas.jpg](https://drive.google.com/uc?export=view&id=142bUyKI5BqOAkXRsYpOQoRCJ3YDOHS5R)\n",
        "\n",
        "\n",
        "* Если вы планируете устроиться на работу в компанию с действительно большой экосистемой данных, знание Spark будет хорошим плюсом и отличает вас от других соискателей.\n",
        "\n",
        "\n",
        "Ознакомиться с экосистемой `Spark`\n",
        " :https://www.kaggle.com/tientd95/pyspark-for-data-science\n",
        "\n",
        "или сомтреть файл `pyspark-for-data-science.ipynb`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIXCFKDrICWk"
      },
      "source": [
        "# **1. Инициализация платформы Spark и загрузка данных в фрейм данных Spark** <a class=\"anchor\" id=\"1\"></a>\n",
        "\n",
        "[Go back to table of contents](#0.1)\n",
        "\n",
        "\n",
        "Источник данных `1`: https://drive.google.com/file/d/1yiAp1fFDy3wSqUR0X_btCZPtuczbLwCe/view?usp=drive_link\n",
        "\n",
        "Источник данных `2`: https://disk.yandex.ru/d/HKtMWSuqglgaXg\n",
        "\n",
        "Этот набор данных предназначен для расчета частоты пульса у людей, а также других связанных с этим характеристик: пола, погодных условий, вида спорта, GPS и т.д."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6dELVVJbICWl"
      },
      "outputs": [],
      "source": [
        "# Импорт модулей, не связанныех с PySpark.\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "import matplotlib\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import math\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "from datetime import *\n",
        "import statistics as stats\n",
        "# Это помогает автоматически распечатывать элементы без явного использования «печати».\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIARaCKKTyLk",
        "outputId": "f253f6da-20eb-4b1e-dc02-289acfc04de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QWQV46fT1zn"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq-26boCU0oQ"
      },
      "outputs": [],
      "source": [
        "!mkdir pyspark2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykdUIWLZU78N"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuFJri3aVHfw"
      },
      "outputs": [],
      "source": [
        "cd pyspark2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFuls1LuU-fX"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/обработка больших данных/apache_spark/spark_seminar/data/endomondoHR.json.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLj_WcCoWL0j"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMTlUnU-WPep"
      },
      "outputs": [],
      "source": [
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8ndPyRcICWm"
      },
      "outputs": [],
      "source": [
        "# Импорт модулей, связанных с PySpark.\n",
        "import pyspark\n",
        "from pyspark.rdd import RDD\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql import functions\n",
        "from pyspark.sql.functions import lit, desc, col, size, array_contains\\\n",
        ", isnan, udf, hour, array_min, array_max, countDistinct\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "MAX_MEMORY = '15G'\n",
        "# Инициализировать сеанс Spark.\n",
        "conf = pyspark.SparkConf().setMaster(\"local[*]\") \\\n",
        "        .set('spark.executor.heartbeatInterval', 10000) \\\n",
        "        .set('spark.network.timeout', 10000) \\\n",
        "        .set(\"spark.core.connection.ack.wait.timeout\", \"3600\") \\\n",
        "        .set(\"spark.executor.memory\", MAX_MEMORY) \\\n",
        "        .set(\"spark.driver.memory\", MAX_MEMORY)\n",
        "def init_spark():\n",
        "    spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"Pyspark guide\") \\\n",
        "        .config(conf=conf) \\\n",
        "        .getOrCreate()\n",
        "    return spark\n",
        "\n",
        "spark = init_spark()\n",
        "filename_data = 'endomondoHR.json' # Загрузите данные в текущий каталог Colab.\n",
        "# filename_data = 'data/endomondoHR.json' # Загрузите данные в каталог data/  при работе в Docker.\n",
        "# Загрузите основной набор данных в фрейм данных pyspark.\n",
        "df = spark.read.json(filename_data, mode=\"DROPMALFORMED\")\n",
        "print('Data frame type: ' + str(type(df)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxmiZJ-eICWn"
      },
      "source": [
        "# **2. Обзор набора данных** <a class=\"anchor\" id=\"2\"></a>\n",
        "\n",
        "[Go back to table of contents](#0.1)\n",
        "\n",
        "### Схема, столбцы и типы данных набора:\n",
        "   *Набор данных содержит как столбцы с одним значением (int, string), так и столбцы, состоящие из списка массивов.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgfcdPNAICWn"
      },
      "outputs": [],
      "source": [
        "print('Обзор данных')\n",
        "df.printSchema()\n",
        "print('Обзор столбцов')\n",
        "pd.DataFrame(df.dtypes, columns = ['Column Name','Data type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-mihzL2ICWn"
      },
      "outputs": [],
      "source": [
        "print('Описание фрейма данных (только строковые и числовые столбцы):')\n",
        "df.describe().toPandas()\n",
        "\n",
        "print(f'Общее количество {df.count()} строк, печатаем несколько первых строк:')\n",
        "df.limit(2).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdQU8PbgICWn"
      },
      "source": [
        "# **3. Обнаружение пропущенных значений и аномальных нулей.** <a class=\"anchor\" id=\"3\"></a>\n",
        "\n",
        "[Go back to table of contents](#0.1)\n",
        "\n",
        "После предварительного просмотра столбцов первое, что должны проверить, — это наличие в наборе данных какого-либо пропущенного значения.\n",
        "– Для строковых столбцов  проверяем наличие `None` и `null`.\n",
        "- Для числовых столбцов проверяем наличие нулей и `NaN`.\n",
        "- Для столбцов типа массив проверяем, содержит ли массив нули или `NaN`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4yuDOrzICWn"
      },
      "outputs": [],
      "source": [
        "print('Обзор столбцов')\n",
        "pd.DataFrame(df.dtypes, columns = ['Column Name','Data type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW2ia5B6ICWo"
      },
      "outputs": [],
      "source": [
        "string_columns = ['gender', 'sport', 'url']\n",
        "numeric_columns = ['id','userId']\n",
        "array_columns = ['altitude', 'heart_rate', 'latitude', 'longitude', 'speed', 'timestamp']\n",
        "missing_values = {}\n",
        "for index, column in enumerate(df.columns):\n",
        "    if column in string_columns:    # проверить столбцы строк со значениями None и Null\n",
        "#         missing_count = df.filter(col(column).eqNullSafe(None) | col(column).isNull()).count()\n",
        "#         missing_values.update({column: missing_count})\n",
        "        missing_count = df.filter(col(column).eqNullSafe(None) | col(column).isNull()).count()\n",
        "        missing_values.update({column:missing_count})\n",
        "    if column in numeric_columns:  # check zeroes, None, NaN\n",
        "        missing_count = df.where(col(column).isin([0,None,np.nan])).count()\n",
        "        missing_values.update({column:missing_count})\n",
        "    if column in array_columns:  # check zeros and NaN\n",
        "        missing_count = df.filter(array_contains(df[column], 0) | array_contains(df[column], np.nan)).count()\n",
        "        missing_values.update({column:missing_count})\n",
        "missing_df = pd.DataFrame.from_dict([missing_values])\n",
        "missing_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cOEhLK1ICWo"
      },
      "outputs": [],
      "source": [
        "#  создаем новый столбец для подсчета количества временных меток, записанных для каждой строки/тренировки, с именем столбца «PerWorkoutRecordCount».\n",
        "df = df.withColumn('PerWorkoutRecordCount', size(col('timestamp')))\n",
        "\n",
        "\n",
        "# Эта часть написана как функция, которую можно будет использовать позже.\n",
        "def user_activity_workout_summarize(df):\n",
        "    user_count = format(df.select('userId').distinct().count(), ',d')\n",
        "    workout_count = format(df.select('id').distinct().count(), ',d')\n",
        "    activity_count = str(df.select('sport').distinct().count())\n",
        "    sum_temp = df.agg(functions.sum('PerWorkoutRecordCount')).toPandas()\n",
        "    total_records_count = format(sum_temp['sum(PerWorkoutRecordCount)'][0],',d')\n",
        "    columns=['Users count', 'Activity types count','Workouts count', 'Total records count']\n",
        "    data = [[user_count], [activity_count], [workout_count], [total_records_count]]\n",
        "    sum_dict = {column: data[i] for i, column in enumerate(columns)}\n",
        "    sum_df = pd.DataFrame.from_dict(sum_dict)[columns]\n",
        "    gender_user_count = df.select('gender','userId').distinct().groupBy('gender').count().toPandas()\n",
        "    gender_activities_count = df.groupBy('gender').count().toPandas()\n",
        "    gender_user_activity_count = gender_user_count.join(\n",
        "        gender_activities_count.set_index('gender'), on='gender'\n",
        "        , how='inner', lsuffix='_gu'\n",
        "    )\n",
        "    gender_user_activity_count.columns = ['Gender', '# of users', 'Activities (workouts) count']\n",
        "\n",
        "    return sum_df, gender_user_activity_count\n",
        "\n",
        "sum_dfs= user_activity_workout_summarize(df)\n",
        "print('\\nОбщая сводка набора данных о пользователях, тренировках и количестве записей (предварительная фильтрация):')\n",
        "sum_dfs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAybjLS7ICWo"
      },
      "source": [
        "Как мы видим, общее количество записей для этого набора данных превышает 111 миллионов записей. Это действительно большой размер"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWjnKsuhICWo"
      },
      "outputs": [],
      "source": [
        "print('Количество тренировок с менее чем 50 записями и статистической сводкой:')\n",
        "removed_df = df.select('PerWorkoutRecordCount').where(df.PerWorkoutRecordCount < 50) \\\n",
        "               .toPandas().describe().astype(int)\n",
        "removed_df.rename(columns = {'PerWorkoutRecordCount': 'PerWorkoutRecordCount <50'}, inplace=True)\n",
        "removed_df.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M2AqH0-ICWo"
      },
      "source": [
        "# **4. Ленивая оценка Pyspark** <a class=\"anchor\" id=\"4\"></a>\n",
        "\n",
        "[Go back to table of contents](#0.1)\n",
        "\n",
        "Здесь мы начнем знакомиться с некоторыми функциями продвинутого `Spark`: **Ленивая оценка**.\n",
        "\n",
        "<font color=\"red\"><b>Ленивая оценка</b></font> расширяет возможности Apache Spark за счет сокращения времени выполнения операций RDD. Он поддерживает граф происхождения для запоминания операций над RDD. мы можем просто помнить, что вся обработка в Pyspark — это абстракция. Когда мы хотим вернуть результаты, мы на самом деле сообщаем Spark, какой конечный ответ вас интересует, и он определяет лучший способ получить его. В результате это оптимизирует производительность и обеспечивает отказоустойчивость.\n",
        "\n",
        "Чтобы увидеть результат, нам нужно вызвать `Spark.collect()`.\n",
        "\n",
        "Обычно можем показать результаты с помощью синтаксиса: `df.take(k)` или `df.limit(k)`, чтобы получить результаты с `k`-строкой.\n",
        "\n",
        "Когда `K` становится большим числом, выполнение этих двух способов, описанных выше, занимает много времени. Потому что приведенный выше синтаксис не использовал возможности обработки `Pyspark` (ленивая оценка).\n",
        "Чтобы быстро обработать, требуется использовать `df.collect()[:k]` для возврата строки `k`, которая нам требуется.\n",
        "\n",
        "Подробнее о ленивых вычислениях `Pyspark` можно прочитать в статье : https://data-flair.training/blogs/apache-spark-lazy-evaluation/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRgRwYtyICWp"
      },
      "outputs": [],
      "source": [
        "ranked_sport_users_df = df.select(df.sport, df.userId) \\\n",
        "    .distinct() \\\n",
        "    .groupBy(df.sport) \\\n",
        "    .count() \\\n",
        "    .orderBy(\"count\", ascending=False)\n",
        "\n",
        "# Топ-5 типов тренировок\n",
        "highest_sport_users_df = ranked_sport_users_df.limit(5).toPandas()\n",
        "# Переименование имени столбца: 'count' -> Users count Количество пользователей.\n",
        "highest_sport_users_df.rename(columns = {'count':'Users count'}, inplace = True)\n",
        "# Подсчет общего количества пользователей. Результат потребуется для подсчета процентного соотношения.\n",
        "total_sports_users = ranked_sport_users_df.groupBy().sum().collect()[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZaCrackICWp"
      },
      "outputs": [],
      "source": [
        "ranked_sport_users_df.collect()[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iNOq25kICWp"
      },
      "source": [
        "# **5. Исследовательский анализ данных** <a class=\"anchor\" id=\"5\"></a>\n",
        "\n",
        "[Go back to table of contents](#0.1)\n",
        "\n",
        "Давайте сначала составим таблицу, указав 5 лучших типов тренировок, которые мы оценили выше."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTLXj44IGBLf"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage for the top 5 sports\n",
        "highest_sport_users_df_renamed['percentage'] = highest_sport_users_df['Users count'] / total_sports_users * 100\n",
        "\n",
        "# Creating the 'others' group\n",
        "others = {\n",
        "    'sport': 'others',\n",
        "    'Users count': total_sports_users - sum(highest_sport_users_df_renamed['Users count']),\n",
        "    'percentage': 100 - sum(highest_sport_users_df_renamed['percentage'])\n",
        "}\n",
        "\n",
        "# Convert 'others' into a DataFrame\n",
        "others_df = pd.DataFrame([others])\n",
        "\n",
        "# Use pd.concat() to append 'others' to the original DataFrame\n",
        "highest_sport_users_df_renamed = pd.concat([highest_sport_users_df_renamed, others_df], ignore_index=True)\n",
        "\n",
        "print('Топ-5 видов спорта, в которых участвует больше всего пользователей:')\n",
        "print(highest_sport_users_df_renamed)\n",
        "\n",
        "# Plotting\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=plt.figaspect(0.35))\n",
        "\n",
        "# Bar plot\n",
        "axs[0].bar(x=highest_sport_users_df_renamed['sport'], height=highest_sport_users_df_renamed['Users count'])\n",
        "axs[0].set_title('Вид спортивных увлечений', fontsize='small')\n",
        "axs[0].set_xlabel('Вид спорта', fontsize='small')\n",
        "axs[0].set_ylabel('Количество пользователей', fontsize='small')\n",
        "axs[0].set_xticklabels(highest_sport_users_df_renamed['sport'], rotation='vertical', fontsize='small')\n",
        "\n",
        "# Pie chart\n",
        "explode = (0.1, 0.1, 0.3, 0.3, 0.3, 0.1)\n",
        "axs[1].pie(\n",
        "    x=highest_sport_users_df_renamed['percentage'],\n",
        "    labels=highest_sport_users_df_renamed['sport'],\n",
        "    autopct='%1.1f%%', shadow=True, explode=explode, startangle=90, radius=1\n",
        ")\n",
        "axs[1].set_title('Вид спортивных увлечений', fontsize='small')\n",
        "\n",
        "# Adding text to the figure\n",
        "fig.text(0.5, 1.02, 'Топ-5 видов спорта, в которых участвует больше всего пользователей', ha='center', va='top', transform=fig.transFigure)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYFG1MJiICWp"
      },
      "source": [
        "Данные показывают, что пользователи тратят наибольшую часть затрат на занятия, связанные с бегом, ходьбой и ездой на велосипеде, что вполне разумно, поскольку эти упражнения удобны без особых вложений 👍"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHJNAOZCICWp"
      },
      "outputs": [],
      "source": [
        "# Просмотр данных в зависимости от пола\n",
        "activities_by_gender = df.groupBy('sport', 'gender').count().toPandas()\n",
        "activities_by_gender[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXF7UQBlICWp"
      },
      "source": [
        "# **6. UNSTACK PYSPARK DATAFRAME** <a class=\"anchor\" id=\"5\"></a>\n",
        "[Go back to table of contents](#0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeCWZV0EICWp"
      },
      "source": [
        "Требуется изменить форму приведенной выше таблицы, чтобы разбить столбец пол, для последующей визуализации.\n",
        "\n",
        "Определим принцип работы с категориями:\n",
        "\n",
        "- метод `DataFrame.stack()`: \"сводит\" уровень (возможно, иерархический) меток столбцов, возвращая a `DataFrame` с новым, самым внутренним уровнем меток строк;\n",
        "\n",
        "- метод `DataFrame.unstack()`: (обратная операция `DataFrame.stack()`) \"сводит\" уровень индекса строки (возможно, иерархический) к оси столбца, создавая измененный `DataFrame` с новым, самым внутренним уровнем меток столбцов.\n",
        "\n",
        "![Spark_vs_Pandas.jpg](https://drive.google.com/uc?export=view&id=1OLmDoS68kKpPLj1bFAPoXKZEjJJcrAeM)\n",
        "\n",
        "Чтобы изменить форму таблицы в Pyspark, мы используем\n",
        "```python\n",
        "df.unstack()\n",
        "```\n",
        "Относительно к нашим данным получим следующее разбиение:\n",
        "\n",
        "![Spark_vs_Pandas.jpg](https://drive.google.com/uc?export=view&id=1lS8DOC-DfsKQOcI0YekPR1lapKpPhXah)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQq8G3ahICWq"
      },
      "outputs": [],
      "source": [
        "total_activities = ranked_sport_users_df.count()\n",
        "print(f'Всего: {total_activities} активности в зависимости от пола:')\n",
        "# Добавление информации о занятиях в зависимости от пола\n",
        "activities_by_gender = df.groupBy('sport', 'gender').count().toPandas()\n",
        "# Визуализация\n",
        "fig = plt.figure(figsize=(12, 25))\n",
        "grid_size = (1,1);\n",
        "ax = plt.subplot2grid(grid_size, (0,0), colspan=1, rowspan=1)\n",
        "plot = activities_by_gender.groupby(['sport', 'gender']).agg(np.mean).groupby(level=0).apply(\n",
        "    lambda x: 100 * x / x.sum()).unstack().plot(kind='barh', stacked=True, width=1  ## APPLY UNSTACK TO RESHAPE DATA\n",
        "                , edgecolor='black', ax=ax, title='Список всех занятий в зависимости от пола')\n",
        "ylabel = plt.ylabel('Sport (Activity)');\n",
        "xlabel = plt.xlabel('Процент участия по гендерному признаку');\n",
        "legend = plt.legend(\n",
        "    sorted(activities_by_gender['gender'].unique()), loc='center left', bbox_to_anchor=(1.0, 0.5)\n",
        ")\n",
        "param_update = plt.rcParams.update({'font.size': 16});\n",
        "ax = plt.gca()\n",
        "formatter = ax.xaxis.set_major_formatter(mtick.PercentFormatter());\n",
        "a = fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtIwDSSZICWq"
      },
      "source": [
        "Давайте посмотрим на верхнее парето из 5 видов спорта, в которых больше всего участников."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me34XwmNHRln"
      },
      "outputs": [],
      "source": [
        "# Pivot the data by gender and sport\n",
        "activities_by_gender_df = activities_by_gender.pivot_table(\n",
        "    index=\"sport\", columns=\"gender\", values='count', fill_value=0) \\\n",
        "    .reset_index().rename_axis(None, axis=1)\n",
        "\n",
        "# Add total count and percentage\n",
        "activities_by_gender_df['total'] = activities_by_gender_df['male'] + activities_by_gender_df['female'] + activities_by_gender_df['unknown']\n",
        "activities_by_gender_df['percentage'] = activities_by_gender_df['total'] / sum(activities_by_gender_df['total']) * 100\n",
        "\n",
        "# Get top 5 activities by percentage\n",
        "top_activities_by_gender_df = activities_by_gender_df.sort_values(by='percentage', ascending=False).head(5)\n",
        "\n",
        "# Create the 'others' group\n",
        "others = {'sport': 'others'}\n",
        "for column in ['female', 'male', 'unknown', 'total', 'percentage']:\n",
        "    value = sum(activities_by_gender_df[column]) - sum(top_activities_by_gender_df[column])\n",
        "    others.update({column: value})\n",
        "\n",
        "# Convert 'others' to a DataFrame\n",
        "others_df = pd.DataFrame([others])\n",
        "\n",
        "# Use pd.concat to add 'others' row to the DataFrame\n",
        "top_activities_by_gender_df = pd.concat([top_activities_by_gender_df, others_df], ignore_index=True)\n",
        "\n",
        "# Sort by percentage again\n",
        "top_activities_by_gender_df = top_activities_by_gender_df.sort_values(by='percentage', ascending=False)\n",
        "\n",
        "# Display the final DataFrame\n",
        "print(top_activities_by_gender_df)\n",
        "\n",
        "# Plotting\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=plt.figaspect(0.35))\n",
        "\n",
        "# Bar plot for total count of activities\n",
        "axs[0].bar(x=top_activities_by_gender_df['sport'], height=top_activities_by_gender_df['total'])\n",
        "axs[0].set_title('Количество тренировок', fontsize='small')\n",
        "axs[0].set_xlabel('Спорт', fontsize='small')\n",
        "axs[0].set_ylabel('Количество тренировок (раз)', fontsize='small')\n",
        "axs[0].set_xticklabels(top_activities_by_gender_df['sport'], rotation='vertical', fontsize='small')\n",
        "\n",
        "# Pie chart for percentage distribution\n",
        "explode = (0.1, 0.1, 0.3, 0.3, 0.3, 0.3)\n",
        "axs[1].pie(\n",
        "    x=top_activities_by_gender_df['percentage'],\n",
        "    labels=top_activities_by_gender_df['sport'],\n",
        "    autopct='%1.1f%%', shadow=True, explode=explode, radius=1\n",
        ")\n",
        "axs[1].set_title('Соотношение тренировок', fontsize='small')\n",
        "\n",
        "# Add text to the figure\n",
        "fig.text(0.5, 1.02, 'Топ-5 видов спорта', ha='center', va='top', transform=fig.transFigure)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI6EVaDtICWq"
      },
      "source": [
        "Опять же, как и в случае с участием пользователей, бег, ходьба и поездки на велосипеде также являются основными факторами, для определния  количества тренировок. Однако единственное отличие состоит в том, что количество занятий бегом и ездой на велосипеде намного больше, чем количество остальных видов спорта, и общее количество этих двух видов уже составляет более 85% от общего количества занятий.\n",
        "\n",
        "Давайте поиграем с каким-нибудь вопросом, например, сколько людей участвовало более чем в одном виде спорта.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn8L6zRJICWq"
      },
      "outputs": [],
      "source": [
        "min_number_of_sports = 1\n",
        "\n",
        "sport_df = df \\\n",
        "    .select(df.userId, df.gender, df.sport) \\\n",
        "    .distinct() \\\n",
        "    .groupBy(df.userId, df.gender) \\\n",
        "    .count()\n",
        "\n",
        "user_more_sports_df = sport_df \\\n",
        "                    .filter(sport_df[\"count\"] > min_number_of_sports) \\\n",
        "                    .orderBy(\"count\", ascending = False) \\\n",
        "                    .toPandas()\n",
        "user_more_sports_df.rename(columns = {'count':'Sports count'}, inplace = True)\n",
        "user_more_sports_df.describe().astype(int).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cOCkiBJICWq"
      },
      "source": [
        "*По итогам 822 человека занимались более чем 1 видом спорта. Среди них в среднем человек занимается примерно 3 видами спорта, а есть кто занимается до 16 видами спорта!* <br />\n",
        "Теперь посмотрим на статистику по полу на коробчатой диаграмме:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKlMicD-ICWq"
      },
      "outputs": [],
      "source": [
        "plot = user_more_sports_df.boxplot(column='Sports count', by='gender', fontsize='small', figsize=(6,7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY0er-KJICWq"
      },
      "source": [
        "*график показал, что, за исключением выбросов, и мужчины, и женщины имеют почти одинаковое распределение участия в спорте..*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM52XIfGICWr"
      },
      "source": [
        "### Распределение количества рекордов за тренировку\n",
        "\n",
        "*Для более детального наблюдения мы разбили количество рекордов по каждому виду деятельности по каждому отдельному виду спорта. <br />Исходя из распределения, максимальное количество записей за тренировку составляет 500, но не все тренировки и виды спорта достигают этого числа.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0T8qmINCICWr"
      },
      "outputs": [],
      "source": [
        "print('\\nГрафик распределения тренировок по видам деятельности:')\n",
        "plot_size_x, plot_size_y = 5, 5\n",
        "figsize_x, figsize_y = plot_size_x * 4 + 3, plot_size_y * 13 + 1\n",
        "figsize=(figsize_x, figsize_y)\n",
        "fig = plt.figure(figsize=figsize) #\n",
        "grid_size = (13,4)\n",
        "ax = plt.subplot2grid(grid_size, (0,0), colspan=1, rowspan=1)\n",
        "#fig, ax = plt.subplots()\n",
        "PerWorkoutRecordCount_dist = df.select('PerWorkoutRecordCount', 'sport').toPandas().hist(\n",
        "    column='PerWorkoutRecordCount', bins=10, sharex = False, grid=True\n",
        "    , xlabelsize='small', ylabelsize='small', by='sport', ax = ax\n",
        "    , layout = grid_size, figsize=figsize\n",
        "    )\n",
        "a = fig.tight_layout()\n",
        "title = fig.text(0.5, 1, 'Распределение количества рекордов за тренировку по видам спорта', ha='center'\n",
        "         , fontsize='small', transform=fig.transFigure);\n",
        "xlabel = fig.text(\n",
        "    0.5, 0.01, '# рекорды/тренировки', va='bottom', ha='center', transform=fig.transFigure\n",
        ")\n",
        "ylabel = fig.text(0.01, 0.5, 'Частота (количество)', va='center', rotation='vertical');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE8N_BaOICWr"
      },
      "outputs": [],
      "source": [
        "# Отфильтровать df с минимум 10 записями (поскольку мы предполагаем, что любой user_id с записью менее 10 не будет иметь смысла)\n",
        "qualified_df = df \\\n",
        "    .select(df.sport, df.userId, df.gender) \\\n",
        "    .groupBy(df.sport, df.userId, df.gender) \\\n",
        "    .count()\n",
        "qualified_df = qualified_df.filter(qualified_df[\"count\"] >= 10) \\\n",
        "    .orderBy(\"count\", ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6bZSSX-ICWr",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print('Количество пользователей, имеющих более 10 тренировок:')\n",
        "qualified_pd_df = qualified_df.select(\"userId\", \"gender\").distinct() \\\n",
        "    .groupBy(qualified_df.gender).count().toPandas()\n",
        "qualified_pd_df.rename(columns={'count': 'Users count'}, inplace=True)\n",
        "qualified_pd_df\n",
        "qualified_users_count = sum(qualified_pd_df['Users count'])\n",
        "total_users_count = df.select('userId').distinct().count()\n",
        "qualified_percentage = round((qualified_users_count / total_users_count),2) * 100\n",
        "print('\\nТаким образом, есть {} / {} пользователей, соответствующих 10 критериям исторических записей, что {:.2f}%' \\\n",
        "      .format(qualified_users_count, total_users_count, qualified_percentage)\n",
        "     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdxUAaFNICWr"
      },
      "source": [
        "# **7. Pyspark UDF** <a class=\"anchor\" id=\"6\"></a>\n",
        "[Go back to table of contents](#0.1)\n",
        "\n",
        "Что такое `UDF`?\n",
        "\n",
        "`User Defined Functions` - это пользовательские функции. Если  знакомы с `SQL`, `UDF` не являются для вас чем-то новым, поскольку большинство традиционных баз данных РСУБД поддерживают пользовательские функции, эти функции необходимо зарегистрировать в библиотеке базы данных и использовать их в `SQL` как обычные функции.\n",
        "\n",
        "`UDF PySpark` аналогичны `UDF` в традиционных базах данных. В `PySpark` создается функция в синтаксисе `Python` и обертываете ее `PySpark SQL udf()` или регистрируете ее как `udf` и используете ее в `DataFrame` и `SQL` соответственно.\n",
        "\n",
        "Зачем нужна `UDF`?\n",
        "\n",
        "`UDF` используются для расширения функций платформы и повторного использования этих функций в нескольких `DataFrame`. Например, требуется преобразовать каждую первую букву слова в строке имени в заглавную; Встроенные функции `PySpark` не имеют этой функции, поэтому можно создать `UDF` и повторно использовать ее по мере необходимости во многих кадрах данных. После создания `UDF` их можно повторно использовать в нескольких выражениях `DataFrame` и `SQL`.\n",
        "\n",
        "Прежде чем создавать какую-либо пользовательскую функцию, изучите, доступна ли аналогичная функция, которая вам нужна, в `Spark SQL Functions` . `PySpark SQL` предоставляет несколько предопределенных общих функций, и с каждым выпуском добавляется множество новых функций, следовательно, лучше всего проверить, прежде чем изобретать велосипед.\n",
        "\n",
        "При создании `UDF`  необходимо проектировать их очень тщательно, иначе столкнетесь с проблемами оптимизации и производительности.\n",
        "\n",
        "Короче говоря, регистрация UDF в Pyspark — это процесс **превращения функций Python в функции PySpark (UDF)**.\n",
        "\n",
        "![Spark_vs_Pandas.jpg](https://drive.google.com/uc?export=view&id=1x5s0p9oa-dNIsNo5XzYQjdMQUxt99WYP)\n",
        "\n",
        "Когда запускаем код в кластерах `Spark`, этот метод ускорит процесс и сэкономит время выполнения.\n",
        "\n",
        "Чтобы узнать больше о `Pyspark UDF`, посетите https://changhsinlee.com/pyspark-udf/.\n",
        "\n",
        "Выполним регистрацию функции Python к UDF в столбце `timestamp`.\n",
        "\n",
        "\n",
        "Этот столбец очень важен, если используем этот набор данных для прогнозирования, например, для прогнозирования частоты пульса, чтобы определить возможные проблемы с сердцем у пользователя фитнес-трекера.\n",
        "\n",
        "### Создание некоторых новых функций из `timestamp`\n",
        "\n",
        "Столбец `timestamp` содержит записи серий временных меток одной тренировки (строка данных) и хранится в формате временных меток `UNIX`. Чтобы получить больше информации об этом столбце,  создадим из него `4` новых столбца:\n",
        "- `date_time`: конвертировать временную метку `UNIX` в формат даты и времени Python.\n",
        "- `duration`: общее время одной тренировки в минутах.\n",
        "   *Чтобы получить «продолжительность» тренировки, получаем разницу между максимальным и минимальным значением списка даты и времени каждой тренировки.*\n",
        "- `workout_start_time`: определим, когда и в какой час дня начинается тренировка.\n",
        "   *Для «workout_start_time» это первая часть записи даты и времени тренировки.*\n",
        "- `interval`: список промежутков времени между каждой отдельной записью временной метки в одной тренировке, в секундах.\n",
        "   *Что касается интервала, рассчитаем его, взяв разницу между двумя последовательными записями временных меток в течение тренировки.*\n",
        "\n",
        "Чтобы прикрепить эти 4 функции к `SparkdDataFrame`,  регистрируем их с помощью `PYSPARK UDF`.\n",
        "\n",
        "```python\n",
        "function_to_udf = udf(function, Datatype())\n",
        "\n",
        "# Datatype() can be floattype(), TimestampType(), etc\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht6-Z7KjICWr"
      },
      "outputs": [],
      "source": [
        "# ПОСМОТРИТЕ СНОВА КОЛОНКУ ВРЕМЕННОЙ МЕТКИ\n",
        "df.limit(3).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rsYEtI5ICWr"
      },
      "source": [
        "### ### Мы создаем 4 вспомогательные функции для столбца 'timestamp', как описано выше, а затем преобразуем их в UDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qbc1JAvICWr",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Преобразование столбца метки времени в Datetime.Datetime, чтобы позже использовать его для функции .withColumn.\n",
        "def to_time(timestamp_list):\n",
        "    # преобразовать в дату и время и минус 7 часов из-за разницы во временном окне Endomondo с временем utc в качестве описания набора данных\n",
        "    return [datetime.fromtimestamp(t) - timedelta(hours=7) for t in timestamp_list]\n",
        "\n",
        "# Регистрация вспомогательной функции to_time в структуре UDF pyspark\n",
        "udf_to_time = udf(to_time, ArrayType(elementType=TimestampType()))\n",
        "\n",
        "# Вспомогательная функция для получения продолжительности (в минутах) списка значений даты и времени, которая будет позже использована для функции withColumn.\n",
        "def get_duration(datetime_list):\n",
        "    time_dif = max(datetime_list) - min(datetime_list)\n",
        "    return time_dif.seconds/60\n",
        "\n",
        "# Регистрация вспомогательной функции get_duration как пользовательской функции в pyspark.\n",
        "udf_get_duration = udf(get_duration, FloatType())\n",
        "\n",
        "# Вспомогательная функция для получения времени начала тренировки из списка даты и времени, которая будет позже использована для функции withColumn.\n",
        "def get_start_time(datetime_list):\n",
        "    return min(datetime_list)\n",
        "\n",
        "# Регистрация вспомогательной функции get_start_time как пользовательской функции в pyspark\n",
        "udf_get_start_time = udf(get_start_time, TimestampType())\n",
        "\n",
        "# Вспомогательная функция для получения списка интервалов во время тренировки\n",
        "def get_interval(datetime_list):\n",
        "    if len(datetime_list) == 1:\n",
        "        return [0]\n",
        "    else:\n",
        "        interval_list = []\n",
        "        for i in range(0, len(datetime_list)-1):\n",
        "            interval = (datetime_list[i+1] - datetime_list[i]).seconds\n",
        "            interval_list.append(interval)\n",
        "        return interval_list\n",
        "\n",
        "# Регистрация вспомогательной функции get_interval как пользовательской функции в pyspark.\n",
        "udf_get_interval = udf(get_interval, ArrayType(elementType=IntegerType()))\n",
        "\n",
        "# Создание нового столбца date_time для преобразования метки времени в формат даты и времени Python для последующего использования.\n",
        "df = df.withColumn('date_time',\n",
        "    udf_to_time('timestamp'))\n",
        "\n",
        "# Создание столбца «workout_start_time», чтобы получить время начала каждой тренировки/строки:\n",
        "df = df.withColumn('workout_start_time', hour(udf_get_start_time('date_time')))\n",
        "\n",
        "# Создание столбца продолжительности из только что созданного столбца date_time, используя функцию udf udf_get_duration, определенную выше.\n",
        "df = df.withColumn('duration', udf_get_duration('date_time'))\n",
        "\n",
        "# Создание столбца интервала из столбца date_time, используя функцию udf udf_get_interval, определенную выше.\n",
        "df = df.withColumn('interval', udf_get_interval('date_time'))\n",
        "\n",
        "print('Новые столбцы (''date_time'', ''workout_start_time'' in hour\\\n",
        ", ''duration'' in minutes & ''interval'' in seconds)\\n, first 5 rows:')\n",
        "df.select('timestamp','date_time', 'workout_start_time', 'duration', 'interval').limit(5).toPandas()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcXDVzeHICWs"
      },
      "source": [
        "### Теперь посмотрим на продолжительность каждой тренировки (в минутах)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rg3q9jw-ICWs"
      },
      "outputs": [],
      "source": [
        "print('\\nСтатистика длительности (в минутах):')\n",
        "df.select('duration').toPandas().describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqKn7c1vICWs"
      },
      "source": [
        "Из статистики столбца `duration` видно, что продолжительность тренировки может длиться от 0 минут до 1 полного дня (1440 минут = 24 часа). Продолжительность 0 может быть для тренировок, которые имеют только одну запись, поэтому минимальная и максимальная отметки времени будут одинаковыми.<br />\n",
        "Теперь пришло время построения графика продолжительности:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJIMqhzMICWs"
      },
      "outputs": [],
      "source": [
        "\n",
        "print('\\nПостроение графика распределения продолжительности по видам спорта:')\n",
        "plot_size_x, plot_size_y = 5, 5\n",
        "figsize_x, figsize_y = plot_size_x * 4 +3, plot_size_y * 13 + 1\n",
        "figsize = (figsize_x, figsize_y)\n",
        "fig = plt.figure(figsize=figsize) #\n",
        "grid_size = (13,4)\n",
        "ax = plt.subplot2grid(grid_size, (0,0), colspan=1, rowspan=1)\n",
        "\n",
        "duration_dist = df.select('duration', 'sport').toPandas().hist(\n",
        "    column='duration', by='sport', bins=15, sharex = False, grid=True\n",
        "    , xlabelsize='small', ylabelsize='small' , ax = ax\n",
        "    , layout = grid_size, figsize=figsize\n",
        "    )\n",
        "a = fig.tight_layout()\n",
        "title = fig.text(0.5, 1, 'Распределение продолжительности тренировок по видам спорта'\n",
        "             , ha='center', va='center', transform=fig.transFigure\n",
        "            )\n",
        "xlabel = fig.text(0.5, 0.01, 'Продолжительность тренировки (минуты)'\n",
        "             , ha='center', va='center', transform=fig.transFigure)\n",
        "ylabel = fig.text(0.01, 0.5, 'Частота (количество)', va='center', rotation='vertical');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6urmq79ICWt"
      },
      "source": [
        "* Судя по сводке продолжительности и графику распределения, большинство занятий происходит в течение 1–2 часов, только несколько видов спорта и несколько случаев каждого типа происходят в течение более длительных периодов, таких как поездка на горном велосипеде, пеший туризм, парусный спорт и т. д. *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfnWQxxrICWt"
      },
      "source": [
        "# **8.Преобразование объектов строк в устойчивый распределенный набор данных Spark (RDD)** <a class=\"anchor\" id=\"7\"></a>\n",
        "[Go back to table of contents](#0.1)\n",
        "\n",
        "На этом графике мы попрактикуемся в преобразовании объекта строки в формат RDD в Pyspark с помощью:\n",
        "\n",
        "```python\n",
        "rdd = df.rdd.map(tuple)\n",
        "or\n",
        "rdd = df.rdd.map(list)\n",
        "```\n",
        "Расширенный формат RDD: каждый набор данных разделен на логические части, которые можно легко вычислить на разных узлах кластера. Они могут работать параллельно и являются отказоустойчивыми, поэтому процесс является стабильным и очень быстрым.\n",
        "\n",
        "Если мы запустим этот код, например, на Zeppelin, который интегрирован с кластерами Pyspark, мы увидим, какова скорость `RDD Spark`.\n",
        "\n",
        "`RDD` — очень важная концепция в `Spark`, можете углубиться в нее здесь:\n",
        "https://www.educba.com/what-is-rdd/\n",
        "\n",
        "Чтобы попрактиковаться в этой концепции,  посмотрим на столбец `interval` и получим по нему некоторую статистику. Рассчитаем некоторые основные статистические данные (мин/макс/среднее/среднее/стандартное отклонение и 4 квантиля 25/50/75/95) в `pySpark`, преобразуем в Rdd и построим их на графике.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m2zL3vDICWt"
      },
      "outputs": [],
      "source": [
        "# Вспомогательная функция для расчета статистики имени столбца из кортежа x (спорт, список записей столбца) tuple x of (sport, records list of the column)\n",
        "#, статистика для расчета также предоставляется в качестве входных данных\n",
        "def calculate_stats(x,column_name, stat_list):\n",
        "    sport, records_list = x\n",
        "    stat_dict = {'sport': sport}\n",
        "    if 'min' in stat_list:\n",
        "        min_stat = min(records_list)\n",
        "        stat_dict.update({'min ' + column_name : min_stat})\n",
        "    if 'max' in stat_list:\n",
        "        max_stat = max(records_list)\n",
        "        stat_dict.update({'max ' + column_name: max_stat})\n",
        "    if 'mean' in stat_list:\n",
        "        average_stat = stats.mean(records_list)\n",
        "        stat_dict.update({'mean ' + column_name: average_stat})\n",
        "    if 'stdev' in stat_list:\n",
        "        std_stat = stats.stdev(records_list)\n",
        "        stat_dict.update({'stdev ' + column_name: std_stat})\n",
        "    if '50th percentile' in stat_list:\n",
        "        median_stat = stats.median(records_list)\n",
        "        stat_dict.update({'50th percentile ' + column_name: median_stat})\n",
        "    if '25th percentile' in stat_list:\n",
        "        percentile_25th_stat = np.percentile(records_list, 25)\n",
        "        stat_dict.update({'25th percentile ' + column_name: percentile_25th_stat})\n",
        "    if '75th percentile' in stat_list:\n",
        "        percentile_75th_stat = np.percentile(records_list, 75)\n",
        "        stat_dict.update({'75th percentile ' + column_name: percentile_75th_stat})\n",
        "    if '95th percentile' in stat_list:\n",
        "        percentile_95th_stat = np.percentile(records_list, 95)\n",
        "        stat_dict.update({'95th percentile ' + column_name: percentile_95th_stat})\n",
        "    return stat_dict\n",
        "\n",
        "def to_list(a):\n",
        "    return a\n",
        "\n",
        "def extend(a, b):\n",
        "    a.extend(b)\n",
        "    return a\n",
        "\n",
        "def retrieve_array_column_stat_df(df, column_name, stat_list):\n",
        "    # Преобразование спорт и «column_name» в RDD, чтобы легко рассчитать статистику интервалов по видам спорта.\n",
        "    sport_record_rdd = df.select('sport', column_name).rdd \\\n",
        "    .map(tuple).combineByKey(to_list, extend, extend).persist()\n",
        "\n",
        "    # Вычислить статистику входного столбца, вызвав функцию Calcul_stats, определенную выше.\n",
        "    record_statistic_df = pd.DataFrame(sport_record_rdd.map(\n",
        "        lambda x: calculate_stats(x, column_name,stat_list)).collect()\n",
        "                                      )\n",
        "    # Установка правильного порядка столбцов данных.\n",
        "    columns_order = ['sport'] + [stat + ' ' + column_name for stat in stat_list]\n",
        "    # Изменение порядка столбцов\n",
        "    return record_statistic_df[columns_order]\n",
        "\n",
        "stat_list = ['min', '25th percentile', 'mean', '50th percentile',\n",
        "                     '75th percentile', '95th percentile', 'max', 'stdev']\n",
        "interval_statistic_df = retrieve_array_column_stat_df(df, column_name='interval', stat_list=stat_list)\n",
        "print('\\nПросмотр статистики интервалов в секундах (по виду спорта)' )\n",
        "interval_statistic_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rG4eegNICWt"
      },
      "source": [
        "Теперь мы отображаем эти числа в виде столбцов (для статистики квантилей) и линейных диаграмм (для мин/макс/среднего/стандартного отклонения) для большей наглядности.\n",
        "*Примечание. Поскольку максимальный интервал и стандартное отклонение имеют гораздо более высокий порядок величины по сравнению с остальными столбцами, нам нужно поместить эти два столбца на отдельную ось Y справа.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpfKlg_PO4Jm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('\\nОбобщенная статистика интервальных видов спорта:')\n",
        "\n",
        "bar_columns = ['25th percentile interval', '50th percentile interval', '75th percentile interval', '95th percentile interval']\n",
        "line_columns1 = ['min interval', 'mean interval']\n",
        "line_columns2 = ['max interval', 'stdev interval']\n",
        "\n",
        "interval_statistic_df = interval_statistic_df.sort_values(by='95th percentile interval', ascending=False)\n",
        "\n",
        "figsize = (13, 59)\n",
        "fig, axs = plt.subplots(nrows=7, figsize=figsize)\n",
        "\n",
        "d = axs[0].set_title('Интервальная статистика по видам спорта', fontsize=18)\n",
        "\n",
        "for i in range(7):\n",
        "    interval_statistic_sub_df = interval_statistic_df.iloc[i*7:i*7+7]\n",
        "\n",
        "    # Plot the bar chart for the quantiles\n",
        "    plot1 = interval_statistic_sub_df[['sport'] + bar_columns].groupby(['sport']).agg(np.mean).plot(\n",
        "        kind='bar', stacked=True, grid=False, alpha=0.5, edgecolor='black', ax=axs[i]\n",
        "    )\n",
        "\n",
        "    # Plot the line chart for min and mean intervals\n",
        "    plot2 = interval_statistic_sub_df[['sport'] + line_columns1].plot(x='sport', ax=axs[i], marker='o')\n",
        "\n",
        "    # Create a secondary y-axis for max and stdev intervals\n",
        "    ax2 = axs[i].twinx()\n",
        "    plot3 = interval_statistic_sub_df[['sport'] + line_columns2].plot(x='sport', ax=ax2, marker='o', color=['m', 'g'])\n",
        "\n",
        "    # Legends for the plots\n",
        "    a = axs[i].legend(loc='center left', fontsize=16, bbox_to_anchor=(1.2, 0.5), frameon=False)\n",
        "    a = ax2.legend(labels=['max interval (right)', 'stdev interval (right)'], loc=\"center left\", fontsize=16, bbox_to_anchor=(1.2, 0.11), frameon=False)\n",
        "\n",
        "    # Formatting for x-ticks and labels\n",
        "    b = axs[i].set_xticklabels(interval_statistic_sub_df['sport'], rotation='horizontal', fontsize='small')\n",
        "    c = axs[i].set_xlabel('Спорт (Активность)', fontsize='small')\n",
        "    d = axs[i].set_ylabel('Статистика квантилей + мин/среднее\\n(секунд)', fontsize=16)\n",
        "    e = ax2.set_ylabel('Max/stdev Statistics\\n(second)', fontsize=16)\n",
        "\n",
        "    # Set font size for y-axis ticks\n",
        "    for tick in axs[i].yaxis.get_major_ticks():\n",
        "        tick.label1.set_fontsize(16)  # Use label1 for primary y-axis labels\n",
        "    ax2.tick_params(axis='y', labelsize=16)\n",
        "\n",
        "    # Make sure x-tick labels are visible for all subplots\n",
        "    b = plt.setp([a.get_xticklabels() for a in fig.axes[:-1]], visible=True)\n",
        "\n",
        "# Adjust the layout for better visualization\n",
        "plt.subplots_adjust(hspace=0.2)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gmVT7IcICWt"
      },
      "source": [
        "до 95% набора интервальных данных не имеют интервала более 400 секунд, в то время как есть лишь несколько выбросов, из-за которых максимальные интервалы достигают 86400 секунд (полных дней)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igGp_rtcICWt"
      },
      "source": [
        "### Время начала тренировки\n",
        "Мы снова используем гистограмму, чтобы посмотреть на распределение часов начала тренировок, сгруппированных по видам спорта и с разбивкой по полу. Мы делим день на интервалы по 2 часа, всего получается 12 частей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XX0QUCrICWt"
      },
      "outputs": [],
      "source": [
        "# Получите таблицу пола, вида спорта и времени начала тренировки для построения графика.\n",
        "start_time_df = df.select('gender', 'sport','workout_start_time').toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnxAi-xiICWt"
      },
      "outputs": [],
      "source": [
        "activities = start_time_df['sport'].unique()\n",
        "plot_size_x, plot_size_y = 5, 5\n",
        "figsize_x, figsize_y = (plot_size_x + 0.5) * 4 +3, (plot_size_y + 1) * 13 + 1\n",
        "\n",
        "\n",
        "nrows, ncols = 13, 4\n",
        "a = fig.subplots_adjust(hspace = 1, wspace = 1)\n",
        "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(figsize_x, figsize_y))\n",
        "print('\\nГрафик распределения времени начала тренировки по видам спорта с разбивкой по полу:')\n",
        "a = plt.setp(axs, xticks=[0, 4, 8, 12, 16, 20])\n",
        "for index, sport in enumerate(activities):\n",
        "    row_index, col_index = divmod(index, ncols)\n",
        "    male_start_time_list = start_time_df[(start_time_df.sport == sport) &\n",
        "                                            (start_time_df.gender == 'male')]['workout_start_time']\n",
        "    female_start_time_list = start_time_df[(start_time_df.sport == sport) &\n",
        "                                            (start_time_df.gender == 'female')]['workout_start_time']\n",
        "    unknown_start_time_list = start_time_df[(start_time_df.sport == sport) &\n",
        "                                            (start_time_df.gender == 'unknown')]['workout_start_time']\n",
        "    if len(male_start_time_list) > 0:\n",
        "        male_dist = axs[row_index, col_index].hist(male_start_time_list,\n",
        "                                      bins = 12, alpha=0.5, label='male', range=(0, 23))\n",
        "    if len(female_start_time_list) > 0:\n",
        "        female_dist = axs[row_index, col_index].hist(female_start_time_list,\n",
        "                                      bins = 12, alpha=0.5, label='female', range=(0, 23))\n",
        "    if len(unknown_start_time_list) > 0:\n",
        "        unknown_dist = axs[row_index, col_index].hist(unknown_start_time_list,\n",
        "                                      bins = 12, alpha=0.5, label = 'unknown', range=(0, 23))\n",
        "    b= axs[row_index, col_index].set_title('Activitiy: ' + sport, fontsize='small')\n",
        "    a = axs[row_index, col_index].legend(loc=\"upper left\", fontsize='small')\n",
        "    a = plt.setp(axs[row_index, col_index].get_xticklabels(), fontsize='small')\n",
        "\n",
        "for i in range(1,4):\n",
        "    x = axs[12, i].set_visible(False)\n",
        "a = fig.tight_layout()\n",
        "z = fig.text(0.5, 1, 'Распределение времени начала тренировки (часы) по видам спорта'\n",
        "             , ha='center', va='top', transform=fig.transFigure)\n",
        "y = fig.text(0.5, 0.01, 'Начало тренировки час в день (час)'\n",
        "             , ha='center', va='bottom', transform=fig.transFigure)\n",
        "z = fig.text(0.02, 0.5, 'Частота (количество)', va='center', rotation='vertical');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J44-iXTrICWu"
      },
      "source": [
        "Из приведенных выше диаграмм распределения видно, что в большинстве видов спорта занятия начинаются либо утром, либо вечером (бимодальное распределение), что имеет смысл. В период с 0 до 4 часов происходит несколько событий, что довольно странно.\n",
        "<br />\n",
        "\n",
        "### Посмотрите глубже на информацию на уровне строки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAEPQ0N9ICWu"
      },
      "outputs": [],
      "source": [
        "stat_list = ['min', '25th percentile', 'mean', '95th percentile', 'max', 'stdev']\n",
        "heart_rate_statistic_df = retrieve_array_column_stat_df(df, column_name='heart_rate', stat_list=stat_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEeoQydTICWu"
      },
      "source": [
        "*Из-за огромного количества пользователей и количества тренировок мы случайным образом выбрали до x количества пользователей каждого пола (например, 5) и до y тренировок по каждому типу активности (например, 10).<br />*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32jgZF7QICWu"
      },
      "outputs": [],
      "source": [
        "# Вспомогательная функция, которая помогает отбирать данные\n",
        "def sampling_data(max_users_per_gender, max_workouts_per_sport):\n",
        "    '''\n",
        "          max_users_per_gender: максимальное количество пользователей, выбираемых случайным образом для каждого пола.\n",
        "          max_workouts_per_sport: максимальное количество занятий, которые можно выбрать для каждого вида спорта.\n",
        "          (виды спорта, существующие у выбранных пользователей)\n",
        "    '''\n",
        "    # Получение уникального списка идентификаторов пользователя и пола для выборки.\n",
        "    users_genders = df.select('userId', 'gender').distinct().toPandas()\n",
        "    #Выбор до трех идентификаторов пользователей каждого пола из уникального списка идентификаторов пользователей.\n",
        "    random_x_users_per_gender = users_genders.groupby('gender')['userId'].apply(\n",
        "                lambda s: s.sample(min(len(s), max_users_per_gender))\n",
        "    )\n",
        "\n",
        "    # Применение фильтра к pyspark dataframe для выборки.\n",
        "    samples_by_gender = df.where(df.userId.isin(list(random_x_users_per_gender)))\n",
        "\n",
        "    # Генерация уникальных идентификаторов занятий и списков видов спорта из выборочного набора данных.\n",
        "    workout_sports = samples_by_gender.select('id', 'sport').distinct().toPandas()\n",
        "    # выбор до 10 идентификаторов занятий для каждого вида спорта.\n",
        "    random_y_workouts_per_sport = workout_sports.groupby('sport')['id'].apply(\n",
        "        lambda s: s.sample(min(len(s), max_workouts_per_sport))\n",
        "    )\n",
        "\n",
        "    # фильтр к выборочному набору данных, чтобы продолжить сокращать количество тренировок для каждого типа активности.\n",
        "    samples_by_gender_and_sport = samples_by_gender.where(df.id.isin(list(random_y_workouts_per_sport)))\n",
        "    return samples_by_gender_and_sport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtNvZubvICWu",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Использование 2 переменных для определения критериев выборки:\n",
        "# максимальное количество пользователей по полу и максимальное количество тренировок по виду спорта\n",
        "max_users_per_gender, max_workouts_per_sport = 20, 15\n",
        "\n",
        "# Сбор набора выборочных данных в Pandas для использования с функциями графика.\n",
        "pd_df = sampling_data(max_users_per_gender, max_workouts_per_sport).toPandas()\n",
        "print('\\nОбзор выборочных данных (только строковые и числовые столбцы)):')\n",
        "pd_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9GJH50wICWu"
      },
      "source": [
        "нормализуем время для всех тренировок, рассчитав продолжительность (в секундах) каждой записи временной метки из первой записи тренировки (первый элемент datetime списка в этой тренировке). <br />\n",
        "Затем отображаем частоту сердечных сокращений в зависимости от этого нормализованного времени, группируя по видам спорта."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRF2_jdhICWu"
      },
      "outputs": [],
      "source": [
        "# Лямбда-функция для объединения списка списков в один большой список\n",
        "flattern = lambda l: set([item for sublist in l for item in sublist])\n",
        "\n",
        "normalized_datetime_list = []\n",
        "for index,data_row in pd_df.iterrows():\n",
        "    min_date_time = min(data_row['date_time'])\n",
        "    normalized_datetime_list.append(\n",
        "        [(date_time - min_date_time).seconds for date_time in data_row['date_time']]\n",
        "    )\n",
        "\n",
        "pd_df['normalized_date_time'] = normalized_datetime_list\n",
        "\n",
        "print('New normalized datetime (first 7 rows):')\n",
        "pd_df.head(7)[['userId', 'sport', 'date_time','normalized_date_time']]\n",
        "\n",
        "print('\\nПостроение необработанного пульс (выборка) по нормированному времени:')\n",
        "\n",
        "sport_list = pd_df['sport'].unique()\n",
        "# Динамическое определение длины фигуры зависит от длины спортивного списка.\n",
        "fig, axs = plt.subplots(len(sport_list), figsize=(15, 6*len(sport_list)))\n",
        "subplot_adj = fig.subplots_adjust(hspace = 0.6)\n",
        "plot_setp = plt.setp(axs, yticks=range(0,250,20))\n",
        "\n",
        "for sport_index, sport in enumerate(sport_list):\n",
        "    workout = pd_df[pd_df.sport == sport]\n",
        "    max_time = max(flattern(workout.normalized_date_time))\n",
        "    for workout_index, data_row in workout.iterrows():\n",
        "        label = 'user: ' + str(data_row['userId']) + ' - gender: ' + data_row['gender']\n",
        "        plot_i = axs[sport_index].plot(\n",
        "            data_row['normalized_date_time'], data_row['heart_rate'], label=label\n",
        "        )\n",
        "    title_i = axs[sport_index].set_title('Activitiy: ' + sport, fontsize='small')\n",
        "    xlabel_i = axs[sport_index].set_xlabel('Time (sec)', fontsize='small')\n",
        "    xsticklabels_i = axs[sport_index].set_xticklabels(\n",
        "        range(0, max_time, 500),rotation = 'vertical', fontsize=9\n",
        "    )\n",
        "    ysticklabels_i = axs[sport_index].set_yticklabels(range(0,250,20),fontsize='small')\n",
        "    legend_i = axs[sport_index].legend(\n",
        "        loc='center left', bbox_to_anchor=(1.0, 0.5), prop={'size': 9}\n",
        "    )\n",
        "\n",
        "x_label = fig.text(0.04, 0.5, 'Частота сердечных сокращений (уд/мин)', va='center', rotation='vertical')\n",
        "chart_title = fig.text(0.5, 1.3, 'Необработанная частота пульса (выборка) по нормализованному времени',\n",
        "            ha='center', va='center', fontsize='small', transform=axs[0].transAxes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g90IraIICWv"
      },
      "source": [
        "### Перемещения во время тренировки\n",
        "У нас будет некоторая визуализация в трех столбцах с информацией о смещении/геометрии (`longitude`,`latitude` и `altitude`).\n",
        "Поскольку  расположение каждого пользователя и тренировки отличается друг от друга, мы отображаем только несколько отдельных тренировок на 3D-графиках, чтобы просмотреть маршрут тренировки.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NysBssdhICWv"
      },
      "outputs": [],
      "source": [
        "pd_df_small = sampling_data(max_users_per_gender=2, max_workouts_per_sport=2).toPandas()\n",
        "print('Sampled data (2 user, 2 workouts per sport):')\n",
        "pd_df_small[['userId', 'gender','sport','id', 'workout_start_time'\n",
        "             ,'PerWorkoutRecordCount', 'duration', 'longitude', 'latitude', 'altitude']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlyWbx-HS0xm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.ticker as mtick\n",
        "import numpy as np  # To use numpy functions for standard deviation\n",
        "\n",
        "def get_fixed_mins_maxs(mins, maxs):\n",
        "    deltas = (maxs - mins) / 12.\n",
        "    mins = mins + deltas / 4.\n",
        "    maxs = maxs - deltas / 4.\n",
        "    return [mins, maxs]\n",
        "\n",
        "workout_count = pd_df_small.shape[0]\n",
        "ncols = 3\n",
        "nrows = math.ceil(workout_count / ncols)\n",
        "\n",
        "fig = plt.figure(figsize=(8 * (ncols + 0.5), 8 * nrows))\n",
        "fig.subplots_adjust(hspace=0.2, wspace=0.5)\n",
        "\n",
        "print('Построение траекторий тренировки в виде 3D для каждой тренировки:')\n",
        "for row_index, row in pd_df_small.iterrows():\n",
        "    min_long = min(row['longitude']) - np.std(row['longitude'])  # Use numpy.std()\n",
        "    max_long = max(row['longitude']) + np.std(row['longitude'])  # Use numpy.std()\n",
        "    minmax_long = get_fixed_mins_maxs(min_long, max_long)\n",
        "\n",
        "    min_lat = min(row['latitude']) - np.std(row['latitude'])  # Use numpy.std()\n",
        "    max_lat = max(row['latitude']) + np.std(row['latitude'])  # Use numpy.std()\n",
        "    minmax_lat = get_fixed_mins_maxs(min_lat, max_lat)\n",
        "\n",
        "    min_alt = min(row['altitude']) - np.std(row['altitude'])  # Use numpy.std()\n",
        "    max_alt = max(row['altitude']) + np.std(row['altitude'])  # Use numpy.std()\n",
        "    minmax_alt = get_fixed_mins_maxs(min_alt, max_alt)\n",
        "\n",
        "    ax = fig.add_subplot(nrows, ncols, row_index + 1, projection='3d')\n",
        "\n",
        "    title = 'Активность: ' + row['sport'] + ' - Пол: ' + row['gender'] + \\\n",
        "            '\\nРекорды: ' + str(int(row['PerWorkoutRecordCount'])) + \\\n",
        "            ' - Длительность: ' + str(int(row['duration'])) + ' минуты'\n",
        "    ax.set_title(title, fontsize=16)\n",
        "\n",
        "    # Scatter plot for points\n",
        "    scatter = ax.scatter(row['longitude'], row['latitude'], row['altitude'], c='r', marker='o')\n",
        "\n",
        "    # Plot the workout path in 3D\n",
        "    plot = ax.plot3D(row['longitude'], row['latitude'], row['altitude'], c='gray', label='Workout path')\n",
        "\n",
        "    # Labels for the axes\n",
        "    ax.set_xlabel('Долгота (градусы)', fontsize=16)\n",
        "    ax.set_ylabel('Широта (градусы)', fontsize=16)\n",
        "    ax.set_zlabel('Высота (м)', fontsize=16, rotation=0)\n",
        "\n",
        "    # Set font size for ticks (accessing `label1` for the primary ticks)\n",
        "    for t in ax.xaxis.get_major_ticks():\n",
        "        t.label1.set_fontsize(16)\n",
        "    for t in ax.yaxis.get_major_ticks():\n",
        "        t.label1.set_fontsize(16)\n",
        "    for t in ax.zaxis.get_major_ticks():\n",
        "        t.label1.set_fontsize(16)\n",
        "\n",
        "    # Add legends\n",
        "    ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
        "\n",
        "    # Set limits for each axis\n",
        "    ax.set_xlim(minmax_long)\n",
        "    ax.set_ylim(minmax_lat)\n",
        "    if minmax_alt[0] != minmax_alt[1]:\n",
        "        ax.set_zlim(minmax_alt)\n",
        "\n",
        "    # Set aspect ratio for the plot (adjust these values as needed)\n",
        "    ax.set_box_aspect([4, 2, 0.5])  # aspect ratio for x, y, z axes\n",
        "\n",
        "    # Remove spines\n",
        "    for spine in ax.spines.values():\n",
        "        spine.set_visible(False)\n",
        "\n",
        "# Add a global title\n",
        "fig.text(0.5, 1.02, \"Маршрут тренировки (долгота/широта/высота)\", ha='center', va='top', fontsize=18)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}